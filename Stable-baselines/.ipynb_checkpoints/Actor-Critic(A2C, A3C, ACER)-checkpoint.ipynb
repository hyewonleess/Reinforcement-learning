{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b1c23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gym\n",
    "from stable_baselines.common.atari_wrappers import make_atari\n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common.vec_env import VecFrameStack\n",
    "from stable_baselines import A2C, ACER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7a6636",
   "metadata": {},
   "source": [
    "# A2C and A3C\n",
    " + `make_atari_env`: Multiprocessing 용 사전 전처리 과정 --> A2C 알고리즘에 4개의 독립적인 환경을 적용하면 실질적으로는 A3C 알고리즘\n",
    " + `make_atari`: Multiprocessing을 적용할 수 없는 환경이라면 사전 전처리를 위하 make_atari를 사용한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beee8fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([[[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]\n",
      "\n",
      " [[0]\n",
      "  [0]\n",
      "  [0]\n",
      "  ...\n",
      "  [0]\n",
      "  [0]\n",
      "  [0]]], [[[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]\n",
      "\n",
      " [[255]\n",
      "  [255]\n",
      "  [255]\n",
      "  ...\n",
      "  [255]\n",
      "  [255]\n",
      "  [255]]], (84, 84, 1), uint8)\n",
      "Box([[[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]\n",
      "\n",
      " [[0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  ...\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]\n",
      "  [0 0 0 0]]], [[[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]\n",
      "\n",
      " [[255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  ...\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]\n",
      "  [255 255 255 255]]], (84, 84, 4), uint8)\n"
     ]
    }
   ],
   "source": [
    "env1 = make_atari_env('PongNoFrameskip-v4', num_env = 4, seed = 0)\n",
    "print(env1.observation_space)\n",
    "\n",
    "env2 = make_atari_env('PongNoFrameskip-v4', num_env = 4, seed = 0)\n",
    "env2 = VecFrameStack(env2, n_stack = 4) # 3D 텐서의 필터 수 4개로 증가\n",
    "print(env2.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48358ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:103: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\distributions.py:327: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:160: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\clip_ops.py:301: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:194: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:196: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "---------------------------------\n",
      "| explained_variance | -152     |\n",
      "| fps                | 17       |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 20       |\n",
      "| value_loss         | 0.00645  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0366   |\n",
      "| fps                | 127      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 2000     |\n",
      "| value_loss         | 0.19     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 884      |\n",
      "| ep_reward_mean     | -20.5    |\n",
      "| explained_variance | 0.159    |\n",
      "| fps                | 131      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 4000     |\n",
      "| value_loss         | 0.000346 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 988      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | -0.0134  |\n",
      "| fps                | 134      |\n",
      "| nupdates           | 300      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 6000     |\n",
      "| value_loss         | 0.18     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 965      |\n",
      "| ep_reward_mean     | -20      |\n",
      "| explained_variance | 0.0112   |\n",
      "| fps                | 134      |\n",
      "| nupdates           | 400      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 8000     |\n",
      "| value_loss         | 0.229    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 979      |\n",
      "| ep_reward_mean     | -20.1    |\n",
      "| explained_variance | 0.0494   |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 500      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 10000    |\n",
      "| value_loss         | 0.000683 |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 955      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | -0.576   |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 600      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 12000    |\n",
      "| value_loss         | 0.00134  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 946      |\n",
      "| ep_reward_mean     | -20.2    |\n",
      "| explained_variance | 0.045    |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 700      |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 14000    |\n",
      "| value_loss         | 0.0851   |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 941      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -0.743   |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 800      |\n",
      "| policy_entropy     | 1.77     |\n",
      "| total_timesteps    | 16000    |\n",
      "| value_loss         | 0.00119  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 933      |\n",
      "| ep_reward_mean     | -20.3    |\n",
      "| explained_variance | -0.0332  |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 900      |\n",
      "| policy_entropy     | 1.76     |\n",
      "| total_timesteps    | 18000    |\n",
      "| value_loss         | 0.144    |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 919      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -0.426   |\n",
      "| fps                | 136      |\n",
      "| nupdates           | 1000     |\n",
      "| policy_entropy     | 1.78     |\n",
      "| total_timesteps    | 20000    |\n",
      "| value_loss         | 0.00196  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 901      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | -0.219   |\n",
      "| fps                | 136      |\n",
      "| nupdates           | 1100     |\n",
      "| policy_entropy     | 1.79     |\n",
      "| total_timesteps    | 22000    |\n",
      "| value_loss         | 0.00197  |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| ep_len_mean        | 901      |\n",
      "| ep_reward_mean     | -20.4    |\n",
      "| explained_variance | 0.013    |\n",
      "| fps                | 135      |\n",
      "| nupdates           | 1200     |\n",
      "| policy_entropy     | 1.78     |\n",
      "| total_timesteps    | 24000    |\n",
      "| value_loss         | 0.00177  |\n",
      "---------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.a2c.a2c.A2C at 0x26dd19c7388>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = make_atari_env('PongNoFrameskip-v4', num_env = 4, seed = 0)\n",
    "env = VecFrameStack(env, n_stack = 4)\n",
    "\n",
    "model = A2C('CnnPolicy', env, verbose = 1)\n",
    "model.learn(total_timesteps = 25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c9152bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'model/c1/w:0' shape=(8, 8, 4, 32) dtype=float32_ref>,\n",
       " <tf.Variable 'model/c1/b:0' shape=(1, 32, 1, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'model/c2/w:0' shape=(4, 4, 32, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'model/c2/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'model/c3/w:0' shape=(3, 3, 64, 64) dtype=float32_ref>,\n",
       " <tf.Variable 'model/c3/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'model/fc1/w:0' shape=(3136, 512) dtype=float32_ref>,\n",
       " <tf.Variable 'model/fc1/b:0' shape=(512,) dtype=float32_ref>,\n",
       " <tf.Variable 'model/vf/w:0' shape=(512, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'model/pi/w:0' shape=(512, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'model/pi/b:0' shape=(6,) dtype=float32_ref>,\n",
       " <tf.Variable 'model/q/w:0' shape=(512, 6) dtype=float32_ref>,\n",
       " <tf.Variable 'model/q/b:0' shape=(6,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CnnPolicy 구조 확인\n",
    "model.get_parameter_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b92967",
   "metadata": {},
   "source": [
    "# ACER\n",
    " + 1개의 on-policy와 n개의 off-policy로 구성된 알고리즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c91cb46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\training\\moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\acer\\acer_simple.py:453: The name tf.global_norm is deprecated. Please use tf.linalg.global_norm instead.\n",
      "\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.91     |\n",
      "| avg_norm_g          | 7.23     |\n",
      "| avg_norm_grads_f    | 6.71     |\n",
      "| avg_norm_k          | 2.45     |\n",
      "| avg_norm_k_dot_g    | 7.23     |\n",
      "| entropy             | 147      |\n",
      "| explained_variance  | -0.134   |\n",
      "| fps                 | 0        |\n",
      "| loss                | -2.18    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -1.27    |\n",
      "| loss_policy         | -1.27    |\n",
      "| loss_q              | 1.12     |\n",
      "| mean_episode_length | 0        |\n",
      "| mean_episode_reward | 0        |\n",
      "| norm_grads          | 933      |\n",
      "| norm_grads_policy   | 831      |\n",
      "| norm_grads_q        | 558      |\n",
      "| total_timesteps     | 80       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.000682 |\n",
      "| avg_norm_g          | 0.65     |\n",
      "| avg_norm_grads_f    | 0.649    |\n",
      "| avg_norm_k          | 2.5      |\n",
      "| avg_norm_k_dot_g    | 0.656    |\n",
      "| entropy             | 144      |\n",
      "| explained_variance  | -1.1     |\n",
      "| fps                 | 47       |\n",
      "| loss                | -1.28    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | 0.157    |\n",
      "| loss_policy         | 0.157    |\n",
      "| loss_q              | 0.00868  |\n",
      "| mean_episode_length | 881      |\n",
      "| mean_episode_reward | -20.5    |\n",
      "| norm_grads          | 0.439    |\n",
      "| norm_grads_policy   | 0.318    |\n",
      "| norm_grads_q        | 0.368    |\n",
      "| total_timesteps     | 8080     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.0818   |\n",
      "| avg_norm_g          | 1.22     |\n",
      "| avg_norm_grads_f    | 1.16     |\n",
      "| avg_norm_k          | 2.57     |\n",
      "| avg_norm_k_dot_g    | 1.27     |\n",
      "| entropy             | 135      |\n",
      "| explained_variance  | 0.131    |\n",
      "| fps                 | 42       |\n",
      "| loss                | -1.41    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.0837  |\n",
      "| loss_policy         | -0.0837  |\n",
      "| loss_q              | 0.0404   |\n",
      "| mean_episode_length | 904      |\n",
      "| mean_episode_reward | -20.4    |\n",
      "| norm_grads          | 0.313    |\n",
      "| norm_grads_policy   | 0.248    |\n",
      "| norm_grads_q        | 0.184    |\n",
      "| total_timesteps     | 16080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.239    |\n",
      "| avg_norm_g          | 2.41     |\n",
      "| avg_norm_grads_f    | 2.24     |\n",
      "| avg_norm_k          | 2.6      |\n",
      "| avg_norm_k_dot_g    | 2.57     |\n",
      "| entropy             | 134      |\n",
      "| explained_variance  | 0.0274   |\n",
      "| fps                 | 40       |\n",
      "| loss                | -1.73    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.451   |\n",
      "| loss_policy         | -0.451   |\n",
      "| loss_q              | 0.117    |\n",
      "| mean_episode_length | 893      |\n",
      "| mean_episode_reward | -20.5    |\n",
      "| norm_grads          | 0.816    |\n",
      "| norm_grads_policy   | 0.392    |\n",
      "| norm_grads_q        | 0.73     |\n",
      "| total_timesteps     | 24080    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| avg_norm_adj        | 0.124    |\n",
      "| avg_norm_g          | 1.51     |\n",
      "| avg_norm_grads_f    | 1.43     |\n",
      "| avg_norm_k          | 2.43     |\n",
      "| avg_norm_k_dot_g    | 1.51     |\n",
      "| entropy             | 145      |\n",
      "| explained_variance  | 0.00895  |\n",
      "| fps                 | 39       |\n",
      "| loss                | -1.59    |\n",
      "| loss_bc             | -0       |\n",
      "| loss_f              | -0.174   |\n",
      "| loss_policy         | -0.174   |\n",
      "| loss_q              | 0.0721   |\n",
      "| mean_episode_length | 880      |\n",
      "| mean_episode_reward | -20.6    |\n",
      "| norm_grads          | 0.386    |\n",
      "| norm_grads_policy   | 0.302    |\n",
      "| norm_grads_q        | 0.27     |\n",
      "| total_timesteps     | 32080    |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = make_atari_env('PongNoFrameskip-v4',num_env=4,seed=1)\n",
    "env = VecFrameStack(env,n_stack=4)\n",
    "\n",
    "model = ACER('CnnLnLstmPolicy',env,verbose=1)\n",
    "model.learn(35000)\n",
    "model.save('acer_pongnoframeskip-v4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5adb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "[<tf.Variable 'model/c1/w:0' shape=(8, 8, 4, 32) dtype=float32_ref>, <tf.Variable 'model/c1/b:0' shape=(1, 32, 1, 1) dtype=float32_ref>, <tf.Variable 'model/c2/w:0' shape=(4, 4, 32, 64) dtype=float32_ref>, <tf.Variable 'model/c2/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'model/c3/w:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'model/c3/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'model/fc1/w:0' shape=(3136, 512) dtype=float32_ref>, <tf.Variable 'model/fc1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(512, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/lstm1/gx:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/lstm1/bx:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/lstm1/gh:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/lstm1/bh:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/lstm1/gc:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'model/lstm1/bc:0' shape=(256,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(256, 6) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(6,) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(256, 6) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(6,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "model = ACER.load('acer_pongnoframeskip-v4')\n",
    "parms = model.get_parameter_list()\n",
    "print(parms)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    obs,rewards,dones,_ = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab06978",
   "metadata": {},
   "source": [
    "<img src=\"render.PNG\" width=\"200\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
