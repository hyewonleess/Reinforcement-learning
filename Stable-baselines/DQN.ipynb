{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2d53352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\ale_py\\roms\\utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\__init__.py:33: UserWarning: stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\n",
      "  \"stable-baselines is in maintenance mode, please use [Stable-Baselines3 (SB3)](https://github.com/DLR-RM/stable-baselines3) for an up-to-date version. You can find a [migration guide](https://stable-baselines3.readthedocs.io/en/master/guide/migration.html) in SB3 documentation.\"\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines import DQN\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21da93",
   "metadata": {},
   "source": [
    "## DQN(Deep Q networks)\n",
    "state이나 action space가 연속형일 경우 동일한 state-action 쌍을 2번 이상 반복하여 Q(s, a)를 추정하는 것은 불가능하다. 만약에 state과 action이 이산형이라도 state/action space의 크기가 크면 Q(s, a)를 계산하는 것이 매우 복잡하다. 이런 문제를 해결하기 위해 Q(s, a)를 딥러닝 모형으로 추정하는데, 이것이 DQN의 핵심이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c9dbe0",
   "metadata": {},
   "source": [
    " 1. `env.reset()`: Step을 실행하다가 episode가 끝나서 이를 초기화한 후 재시작할 때, 초기 state를 반환한다.\n",
    " 2. `env.step(action)`: Action을 1-step 시행한 후, 현재 agent가 관찰한 환경정보인 observation, agent가 실행한 action을 통해 얻은 reward, 에피소드의 종료 여부인 Done, 환경 관련 추가 정보를 나타내는 Info를 출력한다.\n",
    " 3. `env.render()`: GUI로 현재 진행상황을 출력하는 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb611bc",
   "metadata": {},
   "source": [
    "### Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5deb2000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:322: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 62       |\n",
      "| episodes                | 100      |\n",
      "| mean 100 episode reward | 19.1     |\n",
      "| steps                   | 1888     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 200      |\n",
      "| mean 100 episode reward | 58.9     |\n",
      "| steps                   | 7776     |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 300      |\n",
      "| mean 100 episode reward | 114      |\n",
      "| steps                   | 19182    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 400      |\n",
      "| mean 100 episode reward | 120      |\n",
      "| steps                   | 31188    |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| % time spent exploring  | 2        |\n",
      "| episodes                | 500      |\n",
      "| mean 100 episode reward | 131      |\n",
      "| steps                   | 44276    |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:151: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  \"You are calling 'step()' even though this \"\n"
     ]
    }
   ],
   "source": [
    "# 1. 환경 만들기\n",
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# 2. DQN 모형 설정 - policy, 환경\n",
    "model = DQN('MlpPolicy', env, verbose = 1)\n",
    "\n",
    "# 3. Model 학습\n",
    "model.learn(total_timesteps = 50000)\n",
    "\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _states = model.predict(obs, deterministic = True) # deterministic = True: greedy policy\n",
    "    obs, rewards, dones, _ = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0643d34",
   "metadata": {},
   "source": [
    " + 구조: 1D 입력(4,) - MLP 노드 64개 - MLP 노드 64개 - 1D 출력 (2,)\n",
    "  - CartPolve-v1의 state가 (4,) 1D 텐서\n",
    "  - CartPolve-v1의 action이 2개 -> (2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c31d15f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\dqn.py:129: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:358: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:359: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:139: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\policies.py:109: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:147: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:149: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:372: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:415: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\deepq\\build_graph.py:449: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:241: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:242: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "[<tf.Variable 'deepq/eps:0' shape=() dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected/weights:0' shape=(4, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected_1/weights:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected_2/weights:0' shape=(64, 2) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected_2/biases:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected/weights:0' shape=(4, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected_1/weights:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected_2/weights:0' shape=(64, 1) dtype=float32_ref>, <tf.Variable 'deepq/model/state_value/fully_connected_2/biases:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected/weights:0' shape=(4, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected_1/weights:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected_2/weights:0' shape=(64, 2) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected_2/biases:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected/weights:0' shape=(4, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected_1/weights:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected_1/biases:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected_2/weights:0' shape=(64, 1) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/state_value/fully_connected_2/biases:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "#model.save('dqn_cartpole')\n",
    "\n",
    "model = DQN.load('dqn_cartpole')\n",
    "\n",
    "# 딥러닝 Q(s, a)의 아키텍쳐 출력\n",
    "params = model.get_parameter_list()\n",
    "print(params)\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "obs = env.reset()\n",
    "for i in range(1000):\n",
    "    action, _state = model.predict(obs, deterministic = True)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e77c4",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "(시간이 매우 오래 걸림)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1695d06e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines.common.atari_wrappers import make_atari\n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common.vec_env import VecFrameStack\n",
    "from stable_baselines.deepq import CnnPolicy, LnCnnPolicy\n",
    "\n",
    "env = make_atari('MsPacmanNoFrameskip-v0')\n",
    "\n",
    "# MsPacman 환경이 이미지이므로 CnnPolicy 사용\n",
    "agent = DQN(CnnPolicy, env, double_q = True, prioritized_replay = True, policy_kwargs = dict(dueling = False))\n",
    "agent.learn(20000)\n",
    "agent.save('dqn_mspacmannoframeskip-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2b9d77",
   "metadata": {},
   "source": [
    " + 구조: Conv layer 3개 + MLP layer 1개 + Output layer\n",
    "  - Input: (210, 160, 3)\n",
    "  - Conv1: 8x8 kernel (32개)\n",
    "  - Conv2: 4x4 kernel (64개)\n",
    "  - Conv3: 3x3 kernel (64개)\n",
    "  - Flatten(Mlp): 512개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe59e6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'deepq/eps:0' shape=() dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c1/w:0' shape=(8, 8, 3, 32) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c1/b:0' shape=(1, 32, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c2/w:0' shape=(4, 4, 32, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c2/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c3/w:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/c3/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fc1/w:0' shape=(22528, 512) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fc1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected/weights:0' shape=(512, 9) dtype=float32_ref>, <tf.Variable 'deepq/model/action_value/fully_connected/biases:0' shape=(9,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c1/w:0' shape=(8, 8, 3, 32) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c1/b:0' shape=(1, 32, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c2/w:0' shape=(4, 4, 32, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c2/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c3/w:0' shape=(3, 3, 64, 64) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/c3/b:0' shape=(1, 64, 1, 1) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fc1/w:0' shape=(22528, 512) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fc1/b:0' shape=(512,) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected/weights:0' shape=(512, 9) dtype=float32_ref>, <tf.Variable 'deepq/target_q_func/model/action_value/fully_connected/biases:0' shape=(9,) dtype=float32_ref>]\n",
      "Box([[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]], (210, 160, 3), uint8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\gym\\envs\\atari\\environment.py:257: UserWarning: \u001b[33mWARN: We strongly suggest supplying `render_mode` when constructing your environment, e.g., gym.make(ID, render_mode='human'). Using `render_mode` provides access to proper scaling, audio support, and proper framerates.\u001b[0m\n",
      "  \"We strongly suggest supplying `render_mode` when \"\n",
      "C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 스레드 모드가 설정된 후에는 바꿀 수 없습니다\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from stable_baselines import DQN\n",
    "from stable_baselines.common.atari_wrappers import make_atari\n",
    "\n",
    "model = DQN.load('dqn_mspacmannoframeskip-v0')\n",
    "parms = model.get_parameter_list()\n",
    "print(parms)\n",
    "\n",
    "env = make_atari('MsPacmanNoFrameskip-v0')\n",
    "print(env.observation_space)\n",
    "obs = env.reset()\n",
    "for i in range(2000):\n",
    "    action,_state = model.predict(obs, deterministic=True)\n",
    "    obs,rewards,dones,info = env.step(action)\n",
    "    env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
