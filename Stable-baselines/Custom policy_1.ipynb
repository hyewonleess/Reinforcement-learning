{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b515bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from stable_baselines.deepq import MlpPolicy, CnnPolicy\n",
    "from stable_baselines.common.policies import LstmPolicy\n",
    "from stable_baselines.common.policies import MlpLstmPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines import DQN, SAC, A2C, ACER\n",
    "from stable_baselines.common.cmd_util import make_atari_env\n",
    "from stable_baselines.common.vec_env import VecFrameStack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdec2620",
   "metadata": {},
   "source": [
    "# Customize policy \n",
    "\n",
    " 1. policy_kwargs\n",
    " 2. built-in policy를 부모 클래스로 하여 net_arch 설정\n",
    " 3. ActorCriticPolicy를 부모 클래스로 하여 CNN, MLP층 조절"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e74b9cf",
   "metadata": {},
   "source": [
    "## 1. policy_kwargs\n",
    " + Mlp 계열 policy에만 사용 가능\n",
    " + Mlp layer의 노드 수, layer 수를 조정 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1e8f5b",
   "metadata": {},
   "source": [
    "### MLP layer 노드 + layer 수 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d79b954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\policies.py:194: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\layers\\core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_layers.py:57: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\policies.py:216: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\policies.py:63: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:196: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:232: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\tf_util.py:449: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:267: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:294: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:311: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\sac\\sac.py:314: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ent_coef                | 0.81156945  |\n",
      "| ent_coef_loss           | -0.31727538 |\n",
      "| entropy                 | 1.0635351   |\n",
      "| episodes                | 4           |\n",
      "| fps                     | 110         |\n",
      "| mean 100 episode reward | -1.26e+03   |\n",
      "| n_updates               | 701         |\n",
      "| policy_loss             | 17.933578   |\n",
      "| qf1_loss                | 0.15176228  |\n",
      "| qf2_loss                | 0.14846855  |\n",
      "| time_elapsed            | 7           |\n",
      "| total timesteps         | 800         |\n",
      "| value_loss              | 0.18106334  |\n",
      "-----------------------------------------\n",
      "[<tf.Variable 'model/pi/fc0/kernel:0' shape=(3, 32) dtype=float32_ref>, <tf.Variable 'model/pi/fc0/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/pi/fc1/kernel:0' shape=(32, 64) dtype=float32_ref>, <tf.Variable 'model/pi/fc1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/pi/fc2/kernel:0' shape=(64, 128) dtype=float32_ref>, <tf.Variable 'model/pi/fc2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/pi/dense/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/pi/dense/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/dense_1/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/pi/dense_1/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc0/kernel:0' shape=(3, 32) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc0/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc1/kernel:0' shape=(32, 64) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc2/kernel:0' shape=(64, 128) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/fc2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/vf/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/values_fn/vf/vf/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc0/kernel:0' shape=(4, 32) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc0/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc1/kernel:0' shape=(32, 64) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc2/kernel:0' shape=(64, 128) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/fc2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/qf1/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf1/qf1/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc0/kernel:0' shape=(4, 32) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc0/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc1/kernel:0' shape=(32, 64) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc2/kernel:0' shape=(64, 128) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/fc2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/qf2/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/values_fn/qf2/qf2/bias:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/log_ent_coef:0' shape=() dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc0/kernel:0' shape=(3, 32) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc0/bias:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc1/kernel:0' shape=(32, 64) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc1/bias:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc2/kernel:0' shape=(64, 128) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/fc2/bias:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/vf/kernel:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'target/values_fn/vf/vf/bias:0' shape=(1,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.sac import MlpPolicy\n",
    "\n",
    "env = gym.make('Pendulum-v1')\n",
    "\n",
    "# MlpPolicy의 노드 수가 각각 32, 64, 128개인 layer 3개로 설정\n",
    "model = SAC(MlpPolicy, env, verbose = 1, policy_kwargs = dict(layers = [32, 64, 128]))\n",
    "model.learn(1000)\n",
    "params = model.get_parameter_list()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b36cc3",
   "metadata": {},
   "source": [
    "### LSTM layer 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a490a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\common\\distributions.py:326: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\stable_baselines\\a2c\\a2c.py:184: The name tf.train.RMSPropOptimizer is deprecated. Please use tf.compat.v1.train.RMSPropOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\hyewon\\anaconda3\\envs\\base_env\\lib\\site-packages\\tensorflow_core\\python\\training\\rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "---------------------------------\n",
      "| explained_variance | -0.00624 |\n",
      "| fps                | 7        |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 10.7     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.00065  |\n",
      "| fps                | 206      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 6.06     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.00252  |\n",
      "| fps                | 239      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 10.6     |\n",
      "---------------------------------\n",
      "[<tf.Variable 'model/shared_fc0/w:0' shape=(4, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc0/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/shared_fc1/w:0' shape=(32, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc1/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/shared_fc2/w:0' shape=(32, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc2/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(32, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(256, 2) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "# MLP layer에 LSTM layer 추가\n",
    "model = A2C('MlpLstmPolicy', env, verbose = 1, policy_kwargs = dict(net_arch = [32, 32, 32, 'lstm'])) # lstm 층의 노드 수: 256\n",
    "model.learn(total_timesteps = 1000)\n",
    "parms = model.get_parameter_list()\n",
    "print(parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f369b4",
   "metadata": {},
   "source": [
    "### Actor-Critic \n",
    " + pi: actor network \n",
    " + vf: critic network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1710605d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| explained_variance | 0.00205  |\n",
      "| fps                | 6        |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 10.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.0192  |\n",
      "| fps                | 192      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.692    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 3.69     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | -0.00527 |\n",
      "| fps                | 222      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 10.7     |\n",
      "---------------------------------\n",
      "[<tf.Variable 'model/shared_fc0/w:0' shape=(4, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc0/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/shared_fc1/w:0' shape=(32, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc1/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/shared_fc2/w:0' shape=(32, 32) dtype=float32_ref>, <tf.Variable 'model/shared_fc2/b:0' shape=(32,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(32, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/w:0' shape=(256, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/w:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/vf_fc0/w:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'model/vf_fc0/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf_fc1/w:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'model/vf_fc1/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(64, 2) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(128, 2) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "model = A2C('MlpLstmPolicy', env, verbose = 1, policy_kwargs = dict(net_arch = [32,32,32,'lstm',dict(pi = [64,64],vf = [128,128])]))\n",
    "model.learn(total_timesteps = 1000)\n",
    "parms = model.get_parameter_list()\n",
    "print(parms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a5e0ec",
   "metadata": {},
   "source": [
    "## 2. net_arch \n",
    " + CnnPolicy는 커스터마이징 불가 --> net_arch에 지정해도 nature_cnn으로 자동 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf1ed0",
   "metadata": {},
   "source": [
    "MLP층에 LSTM 층을 연결하는 policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dec9995c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]], [[[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]\n",
      "\n",
      " [[255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [255 255 255]\n",
      "  [255 255 255]]], (210, 160, 3), uint8)\n",
      "[<tf.Variable 'model/pi_fc0/w:0' shape=(100800, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/w:0' shape=(64, 64) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/b:0' shape=(64,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(64, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(256, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(256, 9) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(9,) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(256, 9) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(9,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines.common.atari_wrappers import make_atari\n",
    "\n",
    "class CustomPolicy(LstmPolicy): # 부모 클래스: LstmPolicy\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs, feature_extraction = 'mlp')\n",
    "\n",
    "env = make_atari('MsPacmanNoFrameskip-v0')\n",
    "print(env.observation_space)\n",
    "\n",
    "agent = A2C(CustomPolicy, env)\n",
    "agent.learn(1000)\n",
    "params = agent.get_parameter_list()\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9bf6f",
   "metadata": {},
   "source": [
    "부모 클래스를 LstmPolicy로 하는 Actor-critic 알고리즘\n",
    " + 구조: MLP(8개) - LSTM(256개) - actor: [128, 128, 128], critic: [128, 128, 128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93bb03b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| explained_variance | 0.0124   |\n",
      "| fps                | 6        |\n",
      "| nupdates           | 1        |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 5        |\n",
      "| value_loss         | 10.8     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0174   |\n",
      "| fps                | 185      |\n",
      "| nupdates           | 100      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 500      |\n",
      "| value_loss         | 10.6     |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| explained_variance | 0.0148   |\n",
      "| fps                | 213      |\n",
      "| nupdates           | 200      |\n",
      "| policy_entropy     | 0.693    |\n",
      "| total_timesteps    | 1000     |\n",
      "| value_loss         | 10.5     |\n",
      "---------------------------------\n",
      "[<tf.Variable 'model/shared_fc0/w:0' shape=(4, 8) dtype=float32_ref>, <tf.Variable 'model/shared_fc0/b:0' shape=(8,) dtype=float32_ref>, <tf.Variable 'model/lstm1/wx:0' shape=(8, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/wh:0' shape=(256, 1024) dtype=float32_ref>, <tf.Variable 'model/lstm1/b:0' shape=(1024,) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/w:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'model/pi_fc0/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/w:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'model/pi_fc1/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/pi_fc2/w:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'model/pi_fc2/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf_fc0/w:0' shape=(256, 128) dtype=float32_ref>, <tf.Variable 'model/vf_fc0/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf_fc1/w:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'model/vf_fc1/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf_fc2/w:0' shape=(128, 128) dtype=float32_ref>, <tf.Variable 'model/vf_fc2/b:0' shape=(128,) dtype=float32_ref>, <tf.Variable 'model/vf/w:0' shape=(128, 1) dtype=float32_ref>, <tf.Variable 'model/vf/b:0' shape=(1,) dtype=float32_ref>, <tf.Variable 'model/pi/w:0' shape=(128, 2) dtype=float32_ref>, <tf.Variable 'model/pi/b:0' shape=(2,) dtype=float32_ref>, <tf.Variable 'model/q/w:0' shape=(128, 2) dtype=float32_ref>, <tf.Variable 'model/q/b:0' shape=(2,) dtype=float32_ref>]\n"
     ]
    }
   ],
   "source": [
    "class CustomPolicy(LstmPolicy): # 부모 클래스: Lstm --> Actor-Critic 계열 알고리즘 구성\n",
    "    def __init__(self, *args,**kwargs):\n",
    "        super().__init__(*args,**kwargs, \n",
    "                        net_arch=[8,'lstm',dict(pi = [128,128,128],vf = [128,128,128])], feature_extraction='mlp')\n",
    "\n",
    "env = gym.make('CartPole-v1')\n",
    "   \n",
    "model = A2C(CustomPolicy, env, verbose = 1)\n",
    "model.learn(total_timesteps = 1000)\n",
    "parms = model.get_parameter_list()\n",
    "print(parms)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
